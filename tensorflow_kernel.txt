在TensorFlow 中，不是所有的操作都可以被放在GPU 上
不同版本的TensorFlow 对GPU 的支持不一样，如果程序中全部使用强制指定设备的方式会降低程序的可移植性。
在TensorFlow 的kernel①中定义了哪些操作可以跑在GPU 上。

一个比较好的实践是将计算密集型的运算放在GP U 上，而把其他操作放到C P U 上。GPU 是机器中相对独立的资源，将计算放入或者转出GPU 都需要额外的时间。
而且GP U需要将计算时用到的数据从内存复制到GPU 设备上，这也需要额外的时间。Te n sorF l ow 可
以自动完成这些操作而不需要用户特别处理，但为了提高程序运行的速度，用户也需要尽量将相关的运算放在同一个设备上。